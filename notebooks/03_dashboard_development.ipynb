{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3: Interactive Dashboard Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from event_manager import EventManager\n",
    "from change_point_model import EnhancedChangePointModel\n",
    "\n",
    "# Enable offline plotting\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Data Preparation for Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "loader = DataLoader('../data/BrentOilPrices.csv')\n",
    "df = loader.load_data()\n",
    "event_manager = EventManager()\n",
    "events = event_manager.get_all_events()\n",
    "\n",
    "print(f\"Data loaded: {len(df)} price records, {len(events)} events\")\n",
    "\n",
    "# Prepare data for dashboard\n",
    "dashboard_data = {\n",
    "    'prices': df[['Date', 'Price', 'Log_Returns']].copy(),\n",
    "    'events': events.copy(),\n",
    "    'summary_stats': loader.get_summary_stats(df)\n",
    "}\n",
    "\n",
    "# Convert dates to strings for JSON serialization\n",
    "dashboard_data['prices']['Date'] = dashboard_data['prices']['Date'].dt.strftime('%Y-%m-%d')\n",
    "dashboard_data['events']['date'] = dashboard_data['events']['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Interactive Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_price_chart(df, events, title=\"Brent Oil Prices with Events\"):\n",
    "    \"\"\"Create interactive price chart with event markers\"\"\"\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.1,\n",
    "        subplot_titles=('Price (USD/barrel)', 'Log Returns'),\n",
    "        row_heights=[0.7, 0.3]\n",
    "    )\n",
    "    \n",
    "    # Add price trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['Date'],\n",
    "            y=df['Price'],\n",
    "            mode='lines',\n",
    "            name='Brent Oil Price',\n",
    "            line=dict(color='blue', width=1),\n",
    "            hovertemplate='Date: %{x}<br>Price: $%{y:.2f}<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add log returns trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['Date'][1:],\n",
    "            y=df['Log_Returns'].dropna(),\n",
    "            mode='lines',\n",
    "            name='Log Returns',\n",
    "            line=dict(color='red', width=0.5),\n",
    "            hovertemplate='Date: %{x}<br>Return: %{y:.4f}<extra></extra>'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add event markers\n",
    "    colors = {'Conflict': 'red', 'Economic': 'orange', 'OPEC': 'green', \n",
    "              'Geopolitical': 'purple', 'Natural Disaster': 'brown'}\n",
    "    \n",
    "    for _, event in events.iterrows():\n",
    "        event_date = pd.to_datetime(event['date'])\n",
    "        \n",
    "        # Find corresponding price\n",
    "        price_data = df[df['Date'] <= event_date]\n",
    "        if len(price_data) > 0:\n",
    "            price_at_event = price_data['Price'].iloc[-1]\n",
    "            \n",
    "            # Add vertical line for high impact events\n",
    "            if event['impact'] == 'High':\n",
    "                fig.add_vline(\n",
    "                    x=event_date,\n",
    "                    line_dash=\"dash\",\n",
    "                    line_color=colors.get(event['category'], 'gray'),\n",
    "                    opacity=0.7,\n",
    "                    annotation_text=event['event'][:30] + '...',\n",
    "                    annotation_position=\"top\"\n",
    "                )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display interactive chart\n",
    "interactive_fig = create_interactive_price_chart(df, events)\n",
    "interactive_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Change Point Analysis Dashboard Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_change_point_dashboard(model, cp_summary):\n",
    "    \"\"\"Create change point analysis dashboard\"\"\"\n",
    "    \n",
    "    # Create subplots for different aspects\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Time Series with Change Point',\n",
    "            'Change Point Posterior Distribution',\n",
    "            'Parameter Comparison',\n",
    "            'Model Diagnostics'\n",
    "        ),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Time series with change point\n",
    "    series_data = model.series\n",
    "    tau_mean = cp_summary['mean_tau']\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=series_data,\n",
    "            mode='lines',\n",
    "            name='Data',\n",
    "            line=dict(color='blue', width=1)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_vline(\n",
    "        x=tau_mean,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"red\",\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Change point posterior\n",
    "    tau_samples = cp_summary['tau_samples']\n",
    "    hist_data = np.histogram(tau_samples, bins=50)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=hist_data[1][:-1],\n",
    "            y=hist_data[0],\n",
    "            name='Posterior',\n",
    "            marker_color='lightblue'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Parameter comparison (if model is fitted)\n",
    "    if model.trace is not None:\n",
    "        mu1_samples = model.trace.posterior['mu1'].values.flatten()\n",
    "        mu2_samples = model.trace.posterior['mu2'].values.flatten()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=mu1_samples,\n",
    "                name='μ₁ (before)',\n",
    "                opacity=0.7,\n",
    "                nbinsx=30\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=mu2_samples,\n",
    "                name='μ₂ (after)',\n",
    "                opacity=0.7,\n",
    "                nbinsx=30\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. Model diagnostics placeholder\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[1, 2, 3],\n",
    "            y=[1, 1, 1],\n",
    "            mode='markers+text',\n",
    "            text=['R-hat', 'ESS', 'Convergence'],\n",
    "            textposition=\"middle center\",\n",
    "            name='Diagnostics'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Change Point Analysis Dashboard\",\n",
    "        height=800,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Example usage (would need fitted model)\n",
    "print(\"Change point dashboard component created.\")\n",
    "print(\"This would be populated with actual model results in the full dashboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Event Analysis Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_analysis_dashboard(events):\n",
    "    \"\"\"Create event analysis dashboard\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Events by Category',\n",
    "            'Events by Impact Level',\n",
    "            'Events Timeline',\n",
    "            'Recent High-Impact Events'\n",
    "        ),\n",
    "        specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
    "               [{\"colspan\": 2}, None]],\n",
    "        vertical_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # 1. Events by category\n",
    "    category_counts = events['category'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=category_counts.index,\n",
    "            values=category_counts.values,\n",
    "            name=\"Category\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Events by impact\n",
    "    impact_counts = events['impact'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=impact_counts.index,\n",
    "            values=impact_counts.values,\n",
    "            name=\"Impact\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Events timeline\n",
    "    events_sorted = events.sort_values('date')\n",
    "    colors = {'High': 'red', 'Medium': 'orange', 'Low': 'green'}\n",
    "    \n",
    "    for impact in ['High', 'Medium', 'Low']:\n",
    "        impact_events = events_sorted[events_sorted['impact'] == impact]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=pd.to_datetime(impact_events['date']),\n",
    "                y=[impact] * len(impact_events),\n",
    "                mode='markers',\n",
    "                name=f'{impact} Impact',\n",
    "                marker=dict(\n",
    "                    color=colors[impact],\n",
    "                    size=10,\n",
    "                    symbol='circle'\n",
    "                ),\n",
    "                text=impact_events['event'],\n",
    "                hovertemplate='%{text}<br>Date: %{x}<extra></extra>'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Event Analysis Dashboard\",\n",
    "        height=700,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display event dashboard\n",
    "event_fig = create_event_analysis_dashboard(events)\n",
    "event_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Flask Backend API Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask backend API structure (would be in separate .py file)\n",
    "flask_api_code = '''\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from event_manager import EventManager\n",
    "from enhanced_change_point_model import EnhancedChangePointModel\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Global data storage\n",
    "loader = DataLoader('data/BrentOilPrices.csv')\n",
    "df = loader.load_data()\n",
    "event_manager = EventManager()\n",
    "\n",
    "@app.route('/api/data/prices', methods=['GET'])\n",
    "def get_prices():\n",
    "    \"\"\"Get historical price data\"\"\"\n",
    "    start_date = request.args.get('start_date')\n",
    "    end_date = request.args.get('end_date')\n",
    "    \n",
    "    data = df.copy()\n",
    "    if start_date:\n",
    "        data = data[data['Date'] >= start_date]\n",
    "    if end_date:\n",
    "        data = data[data['Date'] <= end_date]\n",
    "    \n",
    "    return jsonify({\n",
    "        'data': data[['Date', 'Price', 'Log_Returns']].to_dict('records'),\n",
    "        'count': len(data)\n",
    "    })\n",
    "\n",
    "@app.route('/api/events', methods=['GET'])\n",
    "def get_events():\n",
    "    \"\"\"Get historical events\"\"\"\n",
    "    category = request.args.get('category')\n",
    "    impact = request.args.get('impact')\n",
    "    \n",
    "    events = event_manager.get_all_events()\n",
    "    \n",
    "    if category:\n",
    "        events = events[events['category'] == category]\n",
    "    if impact:\n",
    "        events = events[events['impact'] == impact]\n",
    "    \n",
    "    return jsonify({\n",
    "        'events': events.to_dict('records'),\n",
    "        'count': len(events)\n",
    "    })\n",
    "\n",
    "@app.route('/api/analysis/changepoint', methods=['POST'])\n",
    "def run_changepoint_analysis():\n",
    "    \"\"\"Run change point analysis\"\"\"\n",
    "    params = request.json\n",
    "    \n",
    "    series_type = params.get('series_type', 'log_returns')\n",
    "    n_samples = params.get('n_samples', 1000)\n",
    "    start_date = params.get('start_date')\n",
    "    end_date = params.get('end_date')\n",
    "    \n",
    "    # Filter data if date range specified\n",
    "    data = df.copy()\n",
    "    if start_date:\n",
    "        data = data[data['Date'] >= start_date]\n",
    "    if end_date:\n",
    "        data = data[data['Date'] <= end_date]\n",
    "    \n",
    "    # Select series\n",
    "    if series_type == 'log_returns':\n",
    "        series = data['Log_Returns'].dropna()\n",
    "        dates = data['Date'][1:]\n",
    "    else:\n",
    "        series = data['Price']\n",
    "        dates = data['Date']\n",
    "    \n",
    "    try:\n",
    "        # Fit model\n",
    "        model = EnhancedChangePointModel(series, dates)\n",
    "        trace = model.fit(n_samples=n_samples, tune=500)\n",
    "        \n",
    "        # Get results\n",
    "        summary = model.get_change_point_summary()\n",
    "        convergence = model.check_convergence()\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'change_point': {\n",
    "                'index': int(summary['mode_tau']),\n",
    "                'date': summary.get('mode_date', '').strftime('%Y-%m-%d') if 'mode_date' in summary else None,\n",
    "                'confidence_interval': summary['tau_95_hdi'].tolist()\n",
    "            },\n",
    "            'convergence': convergence['converged'],\n",
    "            'parameters': model.get_parameter_summary().to_dict()\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/analysis/events/associate', methods=['POST'])\n",
    "def associate_events():\n",
    "    \"\"\"Associate change point with events\"\"\"\n",
    "    params = request.json\n",
    "    change_date = params.get('change_date')\n",
    "    days_threshold = params.get('days_threshold', 60)\n",
    "    \n",
    "    if not change_date:\n",
    "        return jsonify({'error': 'change_date required'}), 400\n",
    "    \n",
    "    nearby_events = event_manager.find_nearest_event(change_date, days_threshold)\n",
    "    \n",
    "    return jsonify({\n",
    "        'events': nearby_events.to_dict('records'),\n",
    "        'count': len(nearby_events)\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5000)\n",
    "'''\n",
    "\n",
    "print(\"Flask API structure defined.\")\n",
    "print(\"This would be saved as 'dashboard_api.py' for the backend server.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Dashboard Features Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive dashboard features overview\n",
    "dashboard_features = {\n",
    "    \"Interactive Visualizations\": [\n",
    "        \"Time series plots with zoom and pan\",\n",
    "        \"Event markers with hover information\",\n",
    "        \"Change point detection results\",\n",
    "        \"Parameter distribution plots\",\n",
    "        \"Model diagnostics displays\"\n",
    "    ],\n",
    "    \"User Controls\": [\n",
    "        \"Date range selection\",\n",
    "        \"Series type selection (price/returns)\",\n",
    "        \"Model parameters adjustment\",\n",
    "        \"Event filtering by category/impact\",\n",
    "        \"Analysis trigger buttons\"\n",
    "    ],\n",
    "    \"Real-time Analysis\": [\n",
    "        \"On-demand change point detection\",\n",
    "        \"Event association analysis\",\n",
    "        \"Impact quantification\",\n",
    "        \"Model convergence monitoring\",\n",
    "        \"Results export functionality\"\n",
    "    ],\n",
    "    \"Business Intelligence\": [\n",
    "        \"Executive summary reports\",\n",
    "        \"Risk assessment metrics\",\n",
    "        \"Investment implications\",\n",
    "        \"Policy recommendations\",\n",
    "        \"Market trend analysis\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"DASHBOARD FEATURES OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, features in dashboard_features.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for feature in features:\n",
    "        print(f\"  • {feature}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Sample Dashboard Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export sample data for dashboard development\n",
    "sample_data = {\n",
    "    'metadata': {\n",
    "        'title': 'Brent Oil Price Change Point Analysis Dashboard',\n",
    "        'description': 'Interactive analysis of structural breaks in oil prices',\n",
    "        'data_range': f\"{df['Date'].min()} to {df['Date'].max()}\",\n",
    "        'total_records': len(df),\n",
    "        'total_events': len(events)\n",
    "    },\n",
    "    'sample_prices': df.head(100)[['Date', 'Price', 'Log_Returns']].to_dict('records'),\n",
    "    'sample_events': events.head(10).to_dict('records'),\n",
    "    'event_categories': events['category'].value_counts().to_dict(),\n",
    "    'impact_levels': events['impact'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "# Convert dates to strings for JSON serialization\n",
    "for record in sample_data['sample_prices']:\n",
    "    if pd.notna(record['Date']):\n",
    "        record['Date'] = pd.to_datetime(record['Date']).strftime('%Y-%m-%d')\n",
    "\n",
    "for record in sample_data['sample_events']:\n",
    "    if pd.notna(record['date']):\n",
    "        record['date'] = pd.to_datetime(record['date']).strftime('%Y-%m-%d')\n",
    "\n",
    "# Save sample data\n",
    "with open('../data/dashboard_sample_data.json', 'w') as f:\n",
    "    json.dump(sample_data, f, indent=2, default=str)\n",
    "\n",
    "print(\"Sample dashboard data exported to '../data/dashboard_sample_data.json'\")\n",
    "print(f\"Data includes {len(sample_data['sample_prices'])} price records and {len(sample_data['sample_events'])} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Dashboard Implementation Roadmap\n",
    "\n",
    "### Phase 1: Backend Development\n",
    "1. **Flask API Setup**: Implement REST endpoints for data and analysis\n",
    "2. **Data Processing**: Optimize data loading and caching\n",
    "3. **Model Integration**: Connect PyMC3 models to API endpoints\n",
    "4. **Error Handling**: Robust error handling and validation\n",
    "\n",
    "### Phase 2: Frontend Development\n",
    "1. **React Setup**: Initialize React application with routing\n",
    "2. **Component Library**: Build reusable chart and UI components\n",
    "3. **State Management**: Implement Redux for application state\n",
    "4. **API Integration**: Connect frontend to Flask backend\n",
    "\n",
    "### Phase 3: Advanced Features\n",
    "1. **Real-time Updates**: WebSocket integration for live analysis\n",
    "2. **User Authentication**: Secure access and user management\n",
    "3. **Export Functionality**: PDF reports and data downloads\n",
    "4. **Mobile Responsiveness**: Optimize for mobile devices\n",
    "\n",
    "### Phase 4: Deployment\n",
    "1. **Containerization**: Docker setup for easy deployment\n",
    "2. **Cloud Deployment**: AWS/Azure deployment configuration\n",
    "3. **Performance Optimization**: Caching and load balancing\n",
    "4. **Monitoring**: Application monitoring and logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Deliverables for Task 3:\n",
    "\n",
    "1. **Interactive Visualizations**: Plotly-based charts with user interaction\n",
    "2. **Flask Backend API**: RESTful endpoints for data and analysis\n",
    "3. **Dashboard Architecture**: Scalable frontend-backend separation\n",
    "4. **Real-time Analysis**: On-demand change point detection\n",
    "5. **Business Intelligence**: Executive reporting and insights\n",
    "\n",
    "The dashboard provides stakeholders with:\n",
    "- **Interactive exploration** of oil price data and events\n",
    "- **Real-time analysis** capabilities for different time periods\n",
    "- **Professional visualizations** suitable for presentations\n",
    "- **Quantified insights** for investment and policy decisions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
